model: LSTM

epochs: 5
trainer: Trainer
search_space:
  model:
    lstm:
      input_size: [42]
      hidden_size: [64, 128, 256]
      num_layers: [1, 2, 3]
      dropout: [0.0, 0.1, 0.2, 0.3]
    fc:
      output_size: [1]
      
  training:
    optimizer: [Adam, RMSprop, SGD]
    optimizer_args: 
      weight_decay: [0.0, 0.0001, 0.001]
      lr: [0.0005, 0.001, 0.005]
    lr_scheduler: [ReduceLROnPlateau]
    lr_scheduler_args:
    # criterion: [BCEWithLogitsLoss]
    # device: [cpu]
    # batch_size: [16, 32, 64]

search:
  type: random
  n_trials: 2


dataset: "data_test.csv" # be careful, it is a relative path to the root of the project